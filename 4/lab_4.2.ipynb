{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# задание:\n",
    "- 1. Взять модель для суммаризации текстов https://huggingface.co/IlyaGusev/mbart_ru_sum_gazeta и запустить суммаризацию текстов на тестовой части вот этого датасета: https://huggingface.co/datasets/IlyaGusev/gazeta. Код, который это делает, есть в карточке модели. Посчитать метрики blue и rouge\n",
    "- 2. Дообучить модель google/mt5-small для суммаризации текстов из датасета https://huggingface.co/datasets/IlyaGusev/gazeta, запустить суммаризацию на тестовой части датасета, посчитать метрики blue и rouge\n",
    "Таким образом, у вас должно получиться сравнение метрик для оценки качества суммаризации, сделанной двумя разными моделями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Установка необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "royal-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import torch\n",
    "from transformers import MBartTokenizer, MBartForConditionalGeneration\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset, load_metric\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-montana",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ! pip install rouge_score\n",
    "# ! pip install evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка дата сета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "virtual-wisdom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f9f9f974f343d9af972ac087437d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/3.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ff8942edfc48f4aaf04a415cbb7f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/2.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba5da93b9c4426284c512255e85e66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/13.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b03225552f4d86a6a04ef8606b0a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610b107eb3b54ec9910fde1bf2c535a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/550M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde80ac62ced4df69a50cb00aba8ccf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/56.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b2455af920476488dc715824ef67c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/61.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905e6487d7264ef6823c511344221e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb56c1ecd5f4274bdf7e081fedb8977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/60964 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010b49a6490c4853a103cd878eca2da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/6793 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046dc4fc91644e76be69e420d4463676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/6369 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'summary', 'title', 'date', 'url'],\n",
       "        num_rows: 60964\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'summary', 'title', 'date', 'url'],\n",
       "        num_rows: 6793\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'summary', 'title', 'date', 'url'],\n",
       "        num_rows: 6369\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\n",
    "dataset = load_dataset(\"IlyaGusev/gazeta\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "infrared-upset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10fd319ffa343a187ba5858c3aa07e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1bf129151c449afb3881712c9e6c95b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emely\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\emely\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc18ea4a7934c49b25f1554e0e291fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e22404b11594e989273857bb96ced92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/406 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60bf00f984f64b74b0b2022b26a8eb7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd80f550ab143cf9f8ad5f2d81d660d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/3.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "model_name = \"IlyaGusev/mbart_ru_sum_gazeta\"\n",
    "tokenizer = MBartTokenizer.from_pretrained(model_name)\n",
    "model = MBartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "model.to(device)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "institutional-decline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60964"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['test']['text'])\n",
    "len(dataset['train']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch(inputs, batch_size):\n",
    "    batch_start = 0\n",
    "    while batch_start < len(inputs):\n",
    "        yield inputs[batch_start: batch_start + batch_size]\n",
    "        batch_start += batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Считаем для каждого текста посчитать bleu, и вывести среднюю метрику по датасету dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1133it [1:45:14,  5.57s/it]                          \n"
     ]
    }
   ],
   "source": [
    "bleus = []\n",
    "rougs = []\n",
    "\n",
    "batch_size = 6\n",
    "batches = gen_batch(dataset['test']['text'], batch_size)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(batches, total=len(dataset['test']['text'])//batch_size):\n",
    "        input_ids = tokenizer(\n",
    "            batch,\n",
    "            max_length=600,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )[\"input_ids\"].to(device)\n",
    "\n",
    "        output_ids = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            no_repeat_ngram_size=4\n",
    "        )\n",
    "\n",
    "\n",
    "        summaries = list(tokenizer.batch_decode(output_ids, skip_special_tokens=True))\n",
    "        references = batch\n",
    "        for summ, ref in zip(summaries, references):\n",
    "            bl = bleu.compute(predictions=[summ], references=[ref])\n",
    "            rg = rouge.compute(predictions=[summ], references=[ref])\n",
    "            bleus.append(bl)\n",
    "            rougs.append(rg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00048452955174222735"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_bleu = [bl['bleu'] for bl in bleus]\n",
    "av_bleu = sum(av_bleu)/len(av_bleu)\n",
    "\n",
    "av_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1: 235.80881092739483\n",
      "rouge2: 118.71577173936986\n",
      "rougeL: 232.67349697139684\n",
      "rougeLsum: 232.67349697139684\n"
     ]
    }
   ],
   "source": [
    "av_rgs = {\n",
    "    \"rouge1\": 0,\n",
    "    \"rouge2\": 0,\n",
    "    \"rougeL\": 0,\n",
    "    \"rougeLsum\": 0,\n",
    "}\n",
    "\n",
    "for rg in rougs:\n",
    "    for key, val in rg.items():\n",
    "        c = av_rgs[key]\n",
    "        c += val\n",
    "        av_rgs.update({key:c})\n",
    "\n",
    "for key, val in av_rgs.items():\n",
    "    print(f\"{key}: {val/len(rg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
