{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity extraction using Fasttext and LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import everything important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "\n",
    "from gensim.models import fasttext as ft\n",
    "# from gensim.models import FastText as ft\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "VALID_BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "EMBED_DIM = 300\n",
    "\n",
    "MODEL_PATH = \"./state_dict.pt\"\n",
    "# TRAINING_FILE = './ner_dataset.csv'\n",
    "TRAINING_FILE = './dataset/ner_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model = ft.load_facebook_vectors(\"cc.en.300.bin\")\n",
    "# fasttext_model = ft.load_fasttext_format(\"cc.en.300.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityDataset:\n",
    "    def __init__(self, texts, tags, max_len):\n",
    "        self.texts = texts\n",
    "        self.tags = tags\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = self.texts[item]\n",
    "        tags = np.array(self.tags[item])\n",
    "\n",
    "        # while np.nan in text:\n",
    "        #     text[text.index(np.nan)] = \"\"\n",
    "\n",
    "        # Усеките текст до указанного значения max_len\n",
    "        if len(text) < self.max_len:\n",
    "            text = text + [''] * (self.max_len - len(text))\n",
    "        else:\n",
    "            text = text[:self.max_len]\n",
    "\n",
    "        # Преобразуйте текст в векторы слов с использованием вашей FastText модели\n",
    "        ids = [fasttext_model[s] for s in text]\n",
    "        # ids = [fasttext_model.wv.get_vector(s) for s in text]\n",
    "\n",
    "        # Создайте маску, чтобы определить, какие элементы являются реальными словами (1), а какие дополнены (0)\n",
    "        mask = [1] * len(text) + [0] * (self.max_len - len(text))\n",
    "\n",
    "        # Дополните или усечите теги до указанного max_len\n",
    "        if len(tags) < self.max_len:\n",
    "            tags = np.pad(tags, (0, self.max_len - len(tags)), mode='constant', constant_values=0)\n",
    "        else:\n",
    "            tags = tags[:self.max_len]\n",
    "\n",
    "        return (torch.tensor(ids, dtype=torch.float32),\n",
    "                torch.tensor(tags, dtype=torch.long),\n",
    "                torch.tensor(mask, dtype=torch.long))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(output, target, mask, num_labels):\n",
    "    lfn = nn.CrossEntropyLoss()\n",
    "    active_loss = mask.view(-1) == 1\n",
    "    active_logits = output.view(-1, num_labels)\n",
    "    active_labels = torch.where(\n",
    "        active_loss,\n",
    "        target.view(-1),\n",
    "        torch.tensor(lfn.ignore_index).type_as(target)\n",
    "    )\n",
    "    loss = lfn(active_logits, active_labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_stat(pred, target, mask):\n",
    "    mask = mask.bool()\n",
    "    pred = torch.masked_select(pred, mask)\n",
    "    target = torch.masked_select(target, mask)\n",
    "    # сколько элементов угадано корректно\n",
    "    # correct = (pred == target).sum().item()\n",
    "    correct = torch.tensor(torch.eq(pred, target).sum().item(),dtype=torch.float32)\n",
    "    # сколько элементов было всего, не считая \"пустых\" с нулями\n",
    "    # total = mask.sum().item()\n",
    "    total = torch.tensor(len(pred), dtype=torch.float32)\n",
    "    return correct, total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "пример того как должно работать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(4.))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_stat(torch.tensor([1,2,3,4,0,0,0,0]), torch.tensor([1,2,3,4,5,5,5,5]), torch.tensor([1,1,1,1,0,0,0,0]))\n",
    "\n",
    "acc_stat(torch.tensor([1,2,3,4,0,0,0,0]), torch.tensor([1,2,3,4,5,5,5,5]), torch.tensor([0,0,0,0,1,1,1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityModel(nn.Module):\n",
    "    def __init__(self, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob,\n",
    "                            batch_first=True, bidirectional=bidirectional)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(\n",
    "        self, \n",
    "        embeds,\n",
    "        hidden\n",
    "    ):\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # Пропустим через дропаут\n",
    "        out = self.dropout(lstm_out)\n",
    "        # Проходите через линейный слой\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        num_directions = 2 if self.lstm.bidirectional else 1\n",
    "        print(\"num_directions\", num_directions)\n",
    "        h_zeros = torch.zeros(self.n_layers * num_directions,\n",
    "                              batch_size, self.hidden_dim,\n",
    "                              dtype=torch.float32, device=device)\n",
    "        c_zeros = torch.zeros(self.n_layers * num_directions,\n",
    "                              batch_size, self.hidden_dim,\n",
    "                              dtype=torch.float32, device=device)\n",
    "\n",
    "        return (h_zeros, c_zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data_path):\n",
    "    df = pd.read_csv(data_path, encoding=\"latin-1\")\n",
    "    df.loc[:, \"Sentence #\"] = df[\"Sentence #\"].fillna(method=\"ffill\")\n",
    "\n",
    "    enc_tag = preprocessing.LabelEncoder()\n",
    "\n",
    "    df.loc[:, \"Tag\"] = enc_tag.fit_transform(df[\"Tag\"])\n",
    "\n",
    "    sentences = df.groupby(\"Sentence #\")[\"Word\"].apply(list).values\n",
    "    tag = df.groupby(\"Sentence #\")[\"Tag\"].apply(list).values\n",
    "    return sentences, tag, enc_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asego\\AppData\\Local\\Temp\\ipykernel_22728\\1373258798.py:3: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.loc[:, \"Sentence #\"] = df[\"Sentence #\"].fillna(method=\"ffill\")\n"
     ]
    }
   ],
   "source": [
    "sentences, tag, enc_tag = process_data(TRAINING_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = {\n",
    "    \"enc_tag\": enc_tag\n",
    "}\n",
    "\n",
    "joblib.dump(meta_data, \"meta.bin\")\n",
    "\n",
    "num_tag = len(list(enc_tag.classes_))\n",
    "\n",
    "# делим на трейн и тест с помощью train_test_split\n",
    "(\n",
    "    train_sentences,\n",
    "    test_sentences,\n",
    "    train_tag,\n",
    "    test_tag\n",
    ") = train_test_split(sentences, tag, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EntityDataset(\n",
    "    texts=train_sentences, tags=train_tag, max_len=MAX_LEN\n",
    ")\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=TRAIN_BATCH_SIZE, num_workers=0,\n",
    "    shuffle=True, drop_last=True\n",
    ")\n",
    "\n",
    "valid_dataset = EntityDataset(\n",
    "    texts=test_sentences, tags=test_tag, max_len=MAX_LEN\n",
    ")\n",
    "\n",
    "valid_data_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset, batch_size=VALID_BATCH_SIZE, num_workers=0,\n",
    "    shuffle=False, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, valid_data_loader):\n",
    "    h = model.init_hidden(VALID_BATCH_SIZE)\n",
    "    losses = []\n",
    "    \n",
    "    correct_sum, total_sum = 0, 0\n",
    "    \n",
    "    for inputs, labels, mask in valid_data_loader:\n",
    "        h = tuple([each.data for each in h])\n",
    "        # отправим inputs, labels и mask на GPU\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        mask = mask.to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "        output, h = model(inputs, h)\n",
    "        loss = loss_fn(output, labels.flatten(), mask, num_tag)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        correct, total = acc_stat(torch.argmax(output, dim=-1).flatten(), labels.flatten(), mask.flatten())\n",
    "        correct_sum += correct\n",
    "        total_sum += total\n",
    "    return losses, correct_sum / total_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "\n",
    "model = EntityModel(num_tag, EMBED_DIM, hidden_dim, n_layers, drop_prob=0.5, bidirectional=False)\n",
    "model.to(device)\n",
    "\n",
    "lr=0.005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_directions 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 97/299 [00:04<00:08, 24.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_directions 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 103/299 [00:06<00:31,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5... Step: 100... Loss: 0.739289... Val Loss: 0.762800 Train Acc: 0.839555 Val Acc: 0.846498\n",
      "Validation loss decreased (inf --> 0.762800).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 199/299 [00:10<00:04, 24.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_directions 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 202/299 [00:11<00:20,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5... Step: 200... Loss: 0.543601... Val Loss: 0.491143 Train Acc: 0.843570 Val Acc: 0.846498\n",
      "Validation loss decreased (0.762800 --> 0.491143).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:15<00:00, 18.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_directions 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_directions 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 4/299 [00:01<01:50,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/5... Step: 300... Loss: 0.472838... Val Loss: 0.344045 Train Acc: 0.867615 Val Acc: 0.886777\n",
      "Validation loss decreased (0.491143 --> 0.344045).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 100/299 [00:05<00:07, 25.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_directions 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 103/299 [00:07<00:42,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/5... Step: 400... Loss: 0.220300... Val Loss: 0.222602 Train Acc: 0.912544 Val Acc: 0.938545\n",
      "Validation loss decreased (0.344045 --> 0.222602).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 199/299 [00:11<00:04, 24.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_directions 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 205/299 [00:13<00:15,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/5... Step: 500... Loss: 0.167140... Val Loss: 0.172367 Train Acc: 0.926581 Val Acc: 0.951215\n",
      "Validation loss decreased (0.222602 --> 0.172367).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:17<00:00, 17.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_directions 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_directions 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/299 [00:01<01:35,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/5... Step: 600... Loss: 0.187312... Val Loss: 0.154255 Train Acc: 0.945888 Val Acc: 0.955231\n",
      "Validation loss decreased (0.172367 --> 0.154255).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 101/299 [00:05<00:08, 24.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_directions 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 104/299 [00:07<00:42,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/5... Step: 700... Loss: 0.158535... Val Loss: 0.150970 Train Acc: 0.953426 Val Acc: 0.955989\n",
      "Validation loss decreased (0.154255 --> 0.150970).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 200/299 [00:11<00:04, 24.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_directions 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 206/299 [00:13<00:15,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/5... Step: 800... Loss: 0.132532... Val Loss: 0.138388 Train Acc: 0.953841 Val Acc: 0.958571\n",
      "Validation loss decreased (0.150970 --> 0.138388).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:17<00:00, 17.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_directions 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_directions 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/299 [00:02<01:25,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/5... Step: 900... Loss: 0.121712... Val Loss: 0.135167 Train Acc: 0.953327 Val Acc: 0.959252\n",
      "Validation loss decreased (0.138388 --> 0.135167).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 102/299 [00:06<00:08, 23.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_directions 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 105/299 [00:08<00:44,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/5... Step: 1000... Loss: 0.139385... Val Loss: 0.129985 Train Acc: 0.957616 Val Acc: 0.960126\n",
      "Validation loss decreased (0.135167 --> 0.129985).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 201/299 [00:12<00:04, 24.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_directions 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 207/299 [00:14<00:15,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/5... Step: 1100... Loss: 0.147673... Val Loss: 0.128872 Train Acc: 0.957413 Val Acc: 0.959986\n",
      "Validation loss decreased (0.129985 --> 0.128872).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:17<00:00, 16.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_directions 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/299 [00:00<00:12, 24.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_directions 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/299 [00:02<01:57,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/5... Step: 1200... Loss: 0.124096... Val Loss: 0.127205 Train Acc: 0.959361 Val Acc: 0.960560\n",
      "Validation loss decreased (0.128872 --> 0.127205).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 102/299 [00:06<00:08, 23.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_directions 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 105/299 [00:08<00:48,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/5... Step: 1300... Loss: 0.121800... Val Loss: 0.125027 Train Acc: 0.959626 Val Acc: 0.960348\n",
      "Validation loss decreased (0.127205 --> 0.125027).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 201/299 [00:12<00:03, 24.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_directions 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 207/299 [00:14<00:15,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/5... Step: 1400... Loss: 0.144627... Val Loss: 0.121615 Train Acc: 0.959518 Val Acc: 0.961748\n",
      "Validation loss decreased (0.125027 --> 0.121615).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:18<00:00, 16.42it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip = 5\n",
    "valid_loss_min = np.Inf\n",
    "writer = SummaryWriter('logs')\n",
    "\n",
    "num_labels = len(list(enc_tag.classes_))\n",
    "\n",
    "model.train()\n",
    "for i in range(EPOCHS):\n",
    "    h = model.init_hidden(TRAIN_BATCH_SIZE)\n",
    "    \n",
    "    correct_sum, total_sum = 0, 0\n",
    "    \n",
    "    for inputs, labels, mask in tqdm(train_data_loader):\n",
    "        counter += 1\n",
    "        h = tuple([e.data for e in h])\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        mask = mask.to(device)\n",
    "        model.zero_grad()\n",
    "        output, h = model(inputs, h)\n",
    "        loss = loss_fn(output, labels.flatten(), mask, num_tag) # вызываем функцию для подсчета лосса\n",
    "        loss.backward() # и делаем обратное распространение ошибки\n",
    "        correct, total = acc_stat(torch.argmax(output, dim=-1).flatten(), labels.flatten(), mask.flatten())# вызываем функцию acc_stat\n",
    "        correct_sum += correct\n",
    "        total_sum += total\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        # градиентный спуск\n",
    "        \n",
    "        if counter % print_every == 0:\n",
    "            model.eval()\n",
    "            val_losses, val_acc = eval_model(model, valid_data_loader)\n",
    "            model.train()\n",
    "            \n",
    "            val_loss = np.mean(val_losses)\n",
    "            writer.add_scalar('train/loss', loss.item(), counter)\n",
    "            writer.add_scalar('val/loss', val_loss, counter)\n",
    "            writer.add_scalar('train/acc', correct_sum / total_sum, counter)\n",
    "            writer.add_scalar('val/acc', val_acc, counter)\n",
    "\n",
    "            print(\"Epoch: {}/{}...\".format(i+1, EPOCHS),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(val_loss),\n",
    "                  \"Train Acc: {:.6f}\".format(correct_sum / total_sum),\n",
    "                  \"Val Acc: {:.6f}\".format(val_acc))\n",
    "                \n",
    "            if np.mean(val_losses) <= valid_loss_min:\n",
    "                torch.save(model.state_dict(), MODEL_PATH)\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
    "                valid_loss_min = np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_directions 1\n",
      "['O' 'O' 'O' 'O' 'B-geo' 'I-geo']\n"
     ]
    }
   ],
   "source": [
    "meta_data = joblib.load(\"meta.bin\")\n",
    "enc_tag = meta_data[\"enc_tag\"]\n",
    "\n",
    "num_tag = len(list(enc_tag.classes_))\n",
    "\n",
    "text = \"\"\"\n",
    "Natasha is traveling to New York\n",
    "\"\"\"\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "\n",
    "# так как это инференс, выключаем расчет градиентов:\n",
    "inputs = torch.tensor([fasttext_model.wv[s] for s in word_tokenize(text)], dtype=torch.float32)\n",
    "inputs = inputs.unsqueeze(0).to(device)\n",
    "h = model.init_hidden(1)\n",
    "tag, h = model(inputs, h)\n",
    "\n",
    "print(\n",
    "    enc_tag.inverse_transform(\n",
    "        tag.argmax(-1).cpu().numpy().reshape(-1)\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
