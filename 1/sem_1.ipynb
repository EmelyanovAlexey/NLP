{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymorphy2\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'inspect' has no attribute 'getargspec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Leason\\NLP\\1\\sem_1.ipynb Ячейка 2\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Leason/NLP/1/sem_1.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mreview_processed\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mreview\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: re\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, x))\u001b[39m.\u001b[39mvalues\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Leason/NLP/1/sem_1.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mreview_processed\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mreview\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: word_tokenize(x))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Leason/NLP/1/sem_1.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m morph \u001b[39m=\u001b[39m pymorphy2\u001b[39m.\u001b[39;49mMorphAnalyzer()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Leason/NLP/1/sem_1.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mreview_morphed\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mreview_processed\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mprogress_apply(\u001b[39mlambda\u001b[39;00m x: [morph\u001b[39m.\u001b[39mparse(word)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnormal_form \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m x])\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pymorphy2\\analyzer.py:224\u001b[0m, in \u001b[0;36mMorphAnalyzer.__init__\u001b[1;34m(self, path, lang, result_type, units, probability_estimator_cls, char_substitutes)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result_type_orig \u001b[39m=\u001b[39m result_type\n\u001b[0;32m    223\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_char_substitutes(char_substitutes)\n\u001b[1;32m--> 224\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_units(units)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pymorphy2\\analyzer.py:235\u001b[0m, in \u001b[0;36mMorphAnalyzer._init_units\u001b[1;34m(self, units_unbound)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m    234\u001b[0m     \u001b[39mfor\u001b[39;00m unit \u001b[39min\u001b[39;00m item[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n\u001b[1;32m--> 235\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_units\u001b[39m.\u001b[39mappend((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_unit(unit), \u001b[39mFalse\u001b[39;00m))\n\u001b[0;32m    236\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_units\u001b[39m.\u001b[39mappend((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_unit(item[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]), \u001b[39mTrue\u001b[39;00m))\n\u001b[0;32m    237\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pymorphy2\\analyzer.py:246\u001b[0m, in \u001b[0;36mMorphAnalyzer._bound_unit\u001b[1;34m(self, unit)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_bound_unit\u001b[39m(\u001b[39mself\u001b[39m, unit):\n\u001b[1;32m--> 246\u001b[0m     unit \u001b[39m=\u001b[39m unit\u001b[39m.\u001b[39;49mclone()\n\u001b[0;32m    247\u001b[0m     unit\u001b[39m.\u001b[39minit(\u001b[39mself\u001b[39m)\n\u001b[0;32m    248\u001b[0m     \u001b[39mreturn\u001b[39;00m unit\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pymorphy2\\units\\base.py:35\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit.clone\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclone\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> 35\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_params())\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pymorphy2\\units\\base.py:76\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit._get_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_params\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     74\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Return a dict with the parameters for this analyzer unit. \"\"\"\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mdict\u001b[39m(\n\u001b[1;32m---> 76\u001b[0m         (key, \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, key, \u001b[39mNone\u001b[39;00m)) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_param_names()\n\u001b[0;32m     77\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pymorphy2\\units\\base.py:70\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit._get_param_names\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m:\n\u001b[0;32m     69\u001b[0m     \u001b[39mreturn\u001b[39;00m []\n\u001b[1;32m---> 70\u001b[0m args, varargs, kw, default \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39;49mgetargspec(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msorted\u001b[39m(args[\u001b[39m1\u001b[39m:])\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'inspect' has no attribute 'getargspec'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\", delimiter='\\t')\n",
    "df = df[df['sentiment'] != 'neautral']\n",
    "df['review_processed'] = df['review'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x)).values\n",
    "df['review_processed'] = df['review'].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "df['review_morphed'] = df['review_processed'].progress_apply(lambda x: [morph.parse(word)[0].normal_form for word in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 26060)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1))\n",
    "X = vectorizer.fit_transform([\" \".join(x) for x in df['review_morphed']])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9770700752068624"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds, test_ds, train_marks, test_marks = train_test_split(X, df['sentiment'], test_size=0.3, random_state=42)\n",
    "\n",
    "reg = LogisticRegression()\n",
    "reg.fit(train_ds, train_marks)\n",
    "predict = reg.predict_log_proba(test_ds)[:, 1]\n",
    "\n",
    "roc_auc_score(test_marks, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# егор\n",
    "# bigrams = Phrases(df['review_processed'].values, min_count=2, threshold=1)\n",
    "# message = \"я недавно купил не хороший товар не рекомендую качество плохое не подойти не первый\".split()\n",
    "# print(message)\n",
    "# print(bigrams.export_phrases())\n",
    "# print(bigram[message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # они работают вот так\n",
    "# from gensim.models import Phrases\n",
    "# documents = [\"Нью Йорк большой город\", \"Нью Йорк\", \"Поеду в Нью Йорк на следующей неделе\"]\n",
    "\n",
    "# sentence_stream = [doc.split(\" \") for doc in documents]\n",
    "# bigram = Phrases(sentence_stream, min_count=2, threshold=1)\n",
    "# sent = ['Он', 'поехал', 'в', 'Нью', 'Йорк']\n",
    "# print(bigram[sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html дока"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
